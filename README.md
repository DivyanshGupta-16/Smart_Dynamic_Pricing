# ðŸš– Smart Dynamic Pricing (Hybrid ML + RL)

A **hybrid machine learning + reinforcement learning system** for simulating and predicting **dynamic ride pricing**.  
The project combines **historical price estimation** (ML) with a **Q-learning agent** (RL) to adaptively adjust prices based on demand, supply, and customer loyalty.

---

## ðŸ“Œ Features
- **Base Price Estimation**
  - Median-based estimator using historical rides (`base_price.py`).
  - Falls back from tight duration window â†’ duration bins â†’ vehicle-type median â†’ global median.
- **Data Preprocessing**
  - Missing value handling.
  - Vehicle type encoding (`Economy â†’ 0`, `Premium â†’ 1`, `Luxury â†’ 2`).
  - State construction from riders, drivers, and loyalty (`preprocessing.py`).
- **Feature Engineering**
  - Buckets riders â†’ `Low`, `Medium`, `High`, `Very High`.
  - Buckets drivers â†’ `Low`, `Medium`, `High`.
  - Loyalty proxy from vehicle type (`Regular`, `Silver`, `Gold`) (`utils.py`).
- **Reinforcement Learning**
  - `DynamicPricingEnv` simulates rides as episodes.
  - `QLearningAgent` learns the best price multiplier.
  - Multipliers: `[0.8Ã—, 1.0Ã—, 1.2Ã—, 1.4Ã—]` (`rl.py`).
- **Interactive Streamlit App**
  - Sidebar for user input (demand, supply, vehicle type, ride duration, base price).
  - Option to auto-estimate base price.
  - Shows RL-chosen multiplier and final price recommendation (`app.py`).

---

## ðŸ“‚ Project Structure
project-root/
â”‚â”€â”€ data/
â”‚ â””â”€â”€ dynamic_pricing.csv # dataset
â”‚
â”‚â”€â”€ src/
â”‚ â”œâ”€â”€ base_price.py # base price estimation logic
â”‚ â”œâ”€â”€ preprocessing.py # data preprocessing + state builder
â”‚ â”œâ”€â”€ rl.py # environment + Q-learning agent
â”‚ â”œâ”€â”€ utils.py # bucket creation helpers
â”‚
â”‚â”€â”€ app.py # Streamlit app
â”‚â”€â”€ README.md # this file
â”‚â”€â”€ requirements.txt # dependencies

yaml
Copy code

---

## ðŸ–¼ï¸ Demo

Here are some screenshots of the Streamlit app in action:

### ðŸ”¹ Base Price
![Home Screenshot](assets\base_price_1x.png)

### ðŸ”¹ More Demand
![Sidebar Screenshot](assets\base_price_1-2x.png)

### ðŸ”¹ More Demand with Less Supply
![Prediction Screenshot](assets\base_price_1-4x.png)

### ðŸ”¹ Estimated Increase in Base Price due to more ride duration
![Details Screenshot](assets\estimated_base_price.png)

---

## âš™ï¸ Installation

1. Clone the repo:
   ```bash
   git clone https://github.com/your-username/smart-dynamic-pricing.git
   cd smart-dynamic-pricing
Create a virtual environment and install dependencies:

bash
Copy code
python -m venv venv
source venv/bin/activate   # (Linux/Mac)
venv\Scripts\activate      # (Windows)

pip install -r requirements.txt
Dependencies (requirements.txt):

shell
Copy code
numpy>=1.21
pandas>=1.3
streamlit>=1.20
ðŸš€ Usage
Place your dataset in data/dynamic_pricing.csv.
The CSV should include at least:

javascript
Copy code
Number_of_Riders, Number_of_Drivers, Vehicle_Type, Expected_Ride_Duration, Historical_Cost_of_Ride
Run the Streamlit app:

bash
Copy code
streamlit run app.py
Use the sidebar to input:

Riders, Drivers

Vehicle type (Economy / Premium / Luxury)

Expected ride duration

Historical cost (optional if auto-estimation enabled)

View results:

Base price (ML estimator or manual input)

RL-chosen multiplier

Final recommended price

ðŸ§  Methodology
ML (Supervised / Statistical):
Estimate base ride price from historical rides.

RL (Q-Learning):
Agent trains on bucketed states â†’ learns best multiplier to maximize reward (= revenue - base cost).

Hybrid Prediction:
Final price = Base Price Ã— RL Multiplier.

ðŸ“Š Example Output
lua
Copy code
Base Price (input): â‚¹120.00
RL Multiplier: 1.20Ã—
---------------------------------
ðŸ’° Final Recommended Price: â‚¹144.00
State = ('High', 'Medium', 'Silver')


âœ¨ Built with Python, Streamlit, Numpy, Pandas, Reinforcement Learning